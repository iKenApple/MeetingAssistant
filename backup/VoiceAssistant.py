import json
import re
import threading
import os
import pyaudio
import wave
import time
import subprocess
import numpy as np
import ast
import sys
import pygame
import requests
import pyttsx3
from gtts import gTTS
from cozepy import COZE_CN_BASE_URL, Coze, TokenAuth
from VoiceprintRecognizer import VoiceprintRecognizer


# é…ç½®ç±»
class Config:
    # éŸ³é¢‘å‚æ•°
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    CHUNK = 2048
    SILENCE_DURATION = 2
    THRESHOLD = 300
    MAX_DURATION = 300

    # è·¯å¾„é…ç½®
    RECORDINGS_DIR = "../recordings"
    SUMMARY_FILE = "summary.mp3"
    AI_RESPONSE_FILE = "ai.mp3"

    # Cozeé…ç½®
    API_TOKEN = 'pat_KOHb9a6TPJWs504SZYdrKdJNiG2a1JLZro9rtSkQHnzHkDl7ViPEBPa64Tiiovjg'
    BASE_URL = COZE_CN_BASE_URL
    WORKFLOW_IDS = {
        'record': '7478326457301008394',
        'guest': '7480057361940725795',
        'summary': '7478981906383781942'
    }


class AudioRecorder:
    def __init__(self):
        self._audio = pyaudio.PyAudio()
        self.frames = []
        self.recording = False
        self.last_active = time.time()
        self.has_voice = False

    def __enter__(self):
        self.stream = self._audio.open(
            format=Config.FORMAT,
            channels=Config.CHANNELS,
            rate=Config.RATE,
            input=True,
            frames_per_buffer=Config.CHUNK
        )
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stream.stop_stream()
        self.stream.close()
        self._audio.terminate()

    def record(self):
        try:
            while True:
                data = self.stream.read(Config.CHUNK, exception_on_overflow=False)
                rms = self._calculate_rms(data)

                if rms > Config.THRESHOLD:
                    if not self.recording:
                        print("\nğŸ™ï¸ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³...")
                        self.recording = True
                        self.frames = []
                    self.last_active = time.time()
                    self.has_voice = True
                    self.frames.append(data)
                elif self.recording:
                    self.frames.append(data)
                    current_time = time.time()

                    if current_time - self.last_active > Config.SILENCE_DURATION:
                        print("\nğŸ”‡ æŒç»­é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                        break

                    if current_time - self.last_active > Config.MAX_DURATION:
                        print("\nâ° å·²è¾¾æœ€é•¿å½•éŸ³æ—¶é•¿")
                        break

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­å½•éŸ³")
            return None

        if not self.has_voice:
            print("\nâŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³")
            return None

        return self._save_recording()

    def _calculate_rms(self, data):
        audio_data = np.frombuffer(data, dtype=np.int16)
        if audio_data.size == 0:
            return 0.0
        return np.sqrt(np.mean(audio_data.astype(np.float64) ** 2))

    def _save_recording(self):
        os.makedirs(Config.RECORDINGS_DIR, exist_ok=True)
        filename = os.path.join(Config.RECORDINGS_DIR, f"recording_{int(time.time())}.wav")
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(Config.CHANNELS)
            wf.setsampwidth(self._audio.get_sample_size(Config.FORMAT))
            wf.setframerate(Config.RATE)
            wf.writeframes(b''.join(self.frames))
        return filename


class CozeClient:
    def __init__(self):
        self.client = Coze(
            auth=TokenAuth(token=Config.API_TOKEN),
            base_url=Config.BASE_URL
        )

    def run_workflow(self, workflow_type, content):
        workflow_id = Config.WORKFLOW_IDS[workflow_type]
        response = self.client.workflows.runs.create(
            workflow_id=workflow_id,
            parameters={"input": content}
        )
        return json.loads(response.data)


class AudioPlayer:
    @staticmethod
    def play(file_path):
        try:
            pygame.mixer.music.load(file_path)
            pygame.mixer.music.play()
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
        except Exception as e:
            print(f"éŸ³é¢‘æ’­æ”¾å¤±è´¥: {str(e)}")


class MeetingManager:
    def __init__(self):
        self.vr = VoiceprintRecognizer()
        self.coze = CozeClient()
        self._init_audio_system()

    def _init_audio_system(self):
        pygame.mixer.init()
        self.pp = pyttsx3.init()
        self._check_microphone()

    def _check_microphone(self):
        try:
            audio = pyaudio.PyAudio()
            if audio.get_device_count() == 0:
                raise RuntimeError("æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡")

            stream = audio.open(
                format=Config.FORMAT,
                channels=Config.CHANNELS,
                rate=Config.RATE,
                input=True,
                frames_per_buffer=Config.CHUNK,
                start=False
            )

            try:
                stream.start_stream()
                for _ in range(3):
                    data = stream.read(Config.CHUNK, exception_on_overflow=False)
                    if len(data) == 0:
                        raise RuntimeError("æ— æ³•ä»éº¦å…‹é£è¯»å–æ•°æ®")
                    if self._calculate_rms(data) > 1000:
                        raise RuntimeError("æ£€æµ‹åˆ°å¼ºçƒˆèƒŒæ™¯å™ªéŸ³ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒ")
            finally:
                stream.stop_stream()
                stream.close()
                audio.terminate()

        except Exception as e:
            print(f"éº¦å…‹é£æ£€æŸ¥å¤±è´¥: {str(e)}")
            print("è¯·æ£€æŸ¥ï¼š1.éº¦å…‹é£æƒé™ 2.è®¾å¤‡è¿æ¥ 3.èƒŒæ™¯å™ªéŸ³")
            sys.exit(1)

    @staticmethod
    def _calculate_rms(data):
        return np.sqrt(np.mean(np.frombuffer(data, dtype=np.int16).astype(np.float64) ** 2))

    def _parallel_process(self, filename):
        result = {'speaker': None, 'score': None, 'text': None}

        def speech_to_text():
            try:
                cmd = f"wenet --language chinese {filename}"
                output = subprocess.run(
                    cmd,
                    shell=True,
                    text=True,
                    capture_output=True,
                    timeout=15
                )
                if dict_match := re.search(r"\{.*?\}", output.stdout.strip()):
                    result['text'] = ast.literal_eval(dict_match.group()).get("text")
            except Exception as e:
                print(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")

        def identify_speaker():
            try:
                speaker, score = self.vr.identify_speaker(filename)
                result.update({'speaker': speaker, 'score': score})
            except Exception as e:
                print(f"å£°çº¹è¯†åˆ«å¤±è´¥: {str(e)}")

        threads = [
            threading.Thread(target=speech_to_text),
            threading.Thread(target=identify_speaker)
        ]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

        return result

    def _process_ai_response(self, content):
        result = {'output': None, 'url': None, 'query': None}

        # ä¼šè®®æ€»ç»“å¤„ç†
        summary_data = self.coze.run_workflow('summary', content)
        if summary_data.get("query") == 1:
            self._handle_summary(summary_data, result)

        # AIå“åº”å¤„ç†
        guest_data = self.coze.run_workflow('guest', content)
        self._handle_guest_response(guest_data, result)

    def _handle_summary(self, data, result):
        result['output'] = f'å°U: {data["output"]}'
        print(f"{result['output']}\n{'=' * 50}")
        self.pp.say(result['output'])
        self.pp.runAndWait()
        #tts = gTTS(text=result['output'], lang='zh-cn')
        #tts.save(os.path.join(Config.RECORDINGS_DIR, Config.SUMMARY_FILE))
        #AudioPlayer.play(os.path.join(Config.RECORDINGS_DIR, Config.SUMMARY_FILE))

    def _handle_guest_response(self, data, result):
        result.update({
            'output': f'å°U: {data["output"]}',
            'url': data["url"]
        })
        if 'å°Uæ”¶åˆ°' not in data["output"]:
            print(f"{result['output']}\n{'=' * 50}")
            response = requests.get(result["url"])
            with open(os.path.join(Config.RECORDINGS_DIR, Config.AI_RESPONSE_FILE), 'wb') as f:
                f.write(response.content)
            AudioPlayer.play(os.path.join(Config.RECORDINGS_DIR, Config.AI_RESPONSE_FILE))

    def run(self):
        while True:
            try:
                with AudioRecorder() as recorder:
                    if filename := recorder.record():
                        start_time = time.time()

                        # å¹¶è¡Œå¤„ç†è¯†åˆ«ä»»åŠ¡
                        result = self._parallel_process(filename)
                        print(f"è¯†åˆ«+è½¬æ–‡å­—è€—æ—¶: {time.time() - start_time:.2f}ç§’")

                        if result.get('text'):
                            print(f"\nğŸ“ è¯†åˆ«ç»“æœ:\n{'=' * 50}")
                            print(f"{result['speaker']}({result['score']}): {result['text']}\n{'=' * 50}")

                            # å¼‚æ­¥ä¿å­˜ä¼šè®®è®°å½•
                            content = f"{result['speaker']}({result['score']}): {result['text']}"
                            threading.Thread(
                                target=self.coze.run_workflow,
                                args=('record', content)
                            ).start()

                            # å¤„ç†AIå“åº”
                            self._process_ai_response(content)

                        print(f"å•æ¬¡å…¨æµç¨‹è€—æ—¶: {time.time() - start_time:.2f}ç§’")

            except Exception as e:
                print(f"è¿è¡Œé”™è¯¯: {str(e)}")
                time.sleep(1)


if __name__ == "__main__":
    MeetingManager().run()